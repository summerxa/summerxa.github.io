<!DOCTYPE html>
<html>
<head>
<link rel="stylesheet" href="style.css">
<title>Alphabet Interpreter | Anne Xia</title>
</head>
<style>
    html {
        background: linear-gradient( rgba(0, 0, 0, 0.5), rgba(0, 0, 0, 0.5) ), url(img/alphabet/alpha_l.png) no-repeat center center fixed;
    }
    
    .image-btn {
        background-color: rgb(255, 190, 60);
        color: rgb(97, 65, 0);
    }
</style>
<body>

<div id="image-view">
    <div style="display:flex; padding:6px; width:75%; justify-content: center;">
        <image id="image-view-img" src="img/critterworld/critter_0.png"/>
    </div>
    <div style="display: flex; flex-direction:column; width: 25%; float:right; padding: 6px; justify-content: space-around; gap: 10px">
        <div style="display: flex; width: 100%; flex-direction: row-reverse; height: 4%">
            <button class="image-btn" id="close" onclick="onCloseClicked()">X</button>
        </div>
        <div style="overflow: auto; height: 90%">
            <p id="image-view-txt">text
            </p>
        </div>
        <div style="display:flex; flex-direction: row; width: 100%; align-self: center; justify-content: space-between; height: 6%">
            <button class="image-btn" id="left" onclick="onLeftClicked()">&lt;</button>
            <p id="image-view-label">Image 1/5</p>
            <button class="image-btn" id="right" onclick="onRightClicked()">&gt;</button>
        </div>
    </div>
</div>

<div class="container">
<div class="content">
    <div class="content1 back">
        <a href="index.html">Back</a>
    </div>
    <div class="content1 internal">

        <h1>Alphabet Interpreter</h1>
        <p><em>Jun-Aug 2023</em></p>
        <!-- <p><em>Jun-Aug 2023</em> | Java, Python, Machine learning, Android development </p> -->

        <p>Created by Anne Xia as an independent project.</p>

        <p>Android app written in Java, utilizes AI to identify ASL alphabet signs from live camera feed.</p>

        <p>Training data used photos of hand gestures taken from online databases. Model connected OpenCV, MediaPipe, and 4-layer fully-connected neural network
            and was trained to classify hand gesture images as letters.
        Used Python to train and test model, integrated final model into mobile app.
        </p>

        <p><a href="https://github.com/summerxa/asl-ai-app">GitHub link</a></p>

        <div id="image-gallery"></div>
    </div>
</div>
</div>

</body>

<script src="gallery_script.js"></script>
<script>
const images = [
    {
        "src": "img/alphabet/alpha_a.png",
        "alt": "Screenshot of the app with a hand signing the letter A.",
        "txt": "The app recognizes this hand gesture as the letter A, with other possible candidates listed below as Y and T.",
        "i": 0
    },
    {
        "src": "img/alphabet/alpha_d.png",
        "alt": "Screenshot of the app with a hand signing the letter D.",
        "txt": "The app recognizes this hand gesture as the letter D, with other possible candidates listed below as I and R.",
        "i": 1
    },
    {
        "src": "img/alphabet/alpha_l.png",
        "alt": "Screenshot of the app with a hand signing the letter L.",
        "txt": "The app recognizes this hand gesture as the letter L, with other possible candidates listed below as T and X.",
        "i": 2
    },
    {
        "src": "img/alphabet/alpha_0.png",
        "alt": "The app icon, an orange background image with a white clipart of a hand.",
        "txt": "The icon for the app, which is used in the launcher and while the app is loading.",
        "i": 3
    }
];

buildGallery(images);
</script>

</html>